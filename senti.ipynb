{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vikas\\anaconda3\\lib\\site-packages\n",
      "Requirement already up-to-date: textblob in c:\\users\\vikas\\anaconda3\\lib\\site-packages\n",
      "Requirement already up-to-date: nltk>=3.1 in c:\\users\\vikas\\anaconda3\\lib\\site-packages (from textblob)\n",
      "Requirement already up-to-date: six in c:\\users\\vikas\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob)\n",
      "Requirement already satisfied: nltk in c:\\users\\vikas\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: six in c:\\users\\vikas\\anaconda3\\lib\\site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install -U textblob\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vikas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os,shutil,requests,csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import textblob\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DownloadArticle():\n",
    "    URL = r'http://www.thehindu.com/archive/print/2017/11/{}/'\n",
    "    BOLD = '\\033[1m';END = '\\033[0m'\n",
    "    DATES = [15,16,17,18,19]\n",
    "    CITIES = ['New Delhi','Mumbai','Bengaluru','Chennai',\n",
    "              'Hyderabad','Kolkata','Kochi','Vijayawada','Visakhapatnam']\n",
    "    header = ['cityname','Article']\n",
    "    print('data will be scrapped from 15th to 19th november')\n",
    "    with open('Articles.csv','w',encoding='utf-8') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        writer.writerow(header)\n",
    "        for x in DATES:\n",
    "            print(BOLD+'\\ngetting articles for '+END + URL.format(x))\n",
    "            resp = requests.get(URL.format(x))\n",
    "            soup = BeautifulSoup(resp.content, 'lxml')\n",
    "            for d in CITIES:\n",
    "                count = 0\n",
    "                print(BOLD + d + END,end='  ') #city\n",
    "                for c in soup.find_all('h4',text=d.lower()):\n",
    "                #print(c.text)\n",
    "\n",
    "                    nex = c.find_next_sibling()\n",
    "                    for UR in nex.find_all('a')[1:2]:\n",
    "                        count+=1\n",
    "                        article = []\n",
    "                        ARTICLEURL = UR.get('href')\n",
    "                        #print(ARTICLEURL)\n",
    "                        res2 = requests.get(ARTICLEURL)\n",
    "                        soup2 = BeautifulSoup(res2.content,'lxml')\n",
    "                        for _ in soup2.find_all(['p'],_class=''):\n",
    "                            article.append(_.text.strip())\n",
    "                        try:\n",
    "                            writer.writerow([d,article])\n",
    "                        except:\n",
    "                            pass\n",
    "                #print(' - done with {} articles'.format(count))\n",
    "    print('DONE..')\n",
    "def transform(x):\n",
    "    final = []\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    _word = TextBlob(x)\n",
    "    _word = _word.words.singularize().lemmatize()\n",
    "    _word = [w for w in _word if w not in stopwords]\n",
    "    return ' '.join(x for x in _word)\n",
    "\n",
    "def analyse():\n",
    "    df = pd.read_csv('Articles.csv')\n",
    "    df['Article'] = df['Article'].apply(lambda x: re.sub(pattern = r'[\\[*\\]*\\\"*,*.*\\n*\\'**\\?*\\:*]',repl = ' ',string = x))\n",
    "    df['Article'] = df.Article.apply(lambda x:transform(x))\n",
    "    df['sentiment'] = df.Article.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    finall = {}\n",
    "    for x in df.cityname.values:\n",
    "        finall[x] = (df.sentiment.loc[df.cityname==x].sum())/(df[df.cityname==x].shape[0])\n",
    "    return finall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data will be scrapped from 15th to 19th november\n",
      "\u001b[1m\n",
      "getting articles for \u001b[0mhttp://www.thehindu.com/archive/print/2017/11/15/\n",
      "\u001b[1mNew Delhi\u001b[0m  \u001b[1mMumbai\u001b[0m  \u001b[1mBengaluru\u001b[0m  \u001b[1mChennai\u001b[0m  \u001b[1mHyderabad\u001b[0m  \u001b[1mKolkata\u001b[0m  \u001b[1mKochi\u001b[0m  \u001b[1mVijayawada\u001b[0m  \u001b[1mVisakhapatnam\u001b[0m  \u001b[1m\n",
      "getting articles for \u001b[0mhttp://www.thehindu.com/archive/print/2017/11/16/\n",
      "\u001b[1mNew Delhi\u001b[0m  \u001b[1mMumbai\u001b[0m  \u001b[1mBengaluru\u001b[0m  \u001b[1mChennai\u001b[0m  \u001b[1mHyderabad\u001b[0m  \u001b[1mKolkata\u001b[0m  \u001b[1mKochi\u001b[0m  \u001b[1mVijayawada\u001b[0m  \u001b[1mVisakhapatnam\u001b[0m  \u001b[1m\n",
      "getting articles for \u001b[0mhttp://www.thehindu.com/archive/print/2017/11/17/\n",
      "\u001b[1mNew Delhi\u001b[0m  \u001b[1mMumbai\u001b[0m  \u001b[1mBengaluru\u001b[0m  \u001b[1mChennai\u001b[0m  \u001b[1mHyderabad\u001b[0m  \u001b[1mKolkata\u001b[0m  \u001b[1mKochi\u001b[0m  \u001b[1mVijayawada\u001b[0m  \u001b[1mVisakhapatnam\u001b[0m  \u001b[1m\n",
      "getting articles for \u001b[0mhttp://www.thehindu.com/archive/print/2017/11/18/\n",
      "\u001b[1mNew Delhi\u001b[0m  \u001b[1mMumbai\u001b[0m  \u001b[1mBengaluru\u001b[0m  \u001b[1mChennai\u001b[0m  \u001b[1mHyderabad\u001b[0m  \u001b[1mKolkata\u001b[0m  \u001b[1mKochi\u001b[0m  \u001b[1mVijayawada\u001b[0m  \u001b[1mVisakhapatnam\u001b[0m  \u001b[1m\n",
      "getting articles for \u001b[0mhttp://www.thehindu.com/archive/print/2017/11/19/\n",
      "\u001b[1mNew Delhi\u001b[0m  \u001b[1mMumbai\u001b[0m  \u001b[1mBengaluru\u001b[0m  \u001b[1mChennai\u001b[0m  \u001b[1mHyderabad\u001b[0m  \u001b[1mKolkata\u001b[0m  \u001b[1mKochi\u001b[0m  \u001b[1mVijayawada\u001b[0m  \u001b[1mVisakhapatnam\u001b[0m  DONE..\n"
     ]
    }
   ],
   "source": [
    "# run this if you want to download articles \n",
    "DownloadArticle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bengaluru': 0.071024434771772713,\n",
       " 'Chennai': 0.083531374897821017,\n",
       " 'Hyderabad': 0.093896830965444184,\n",
       " 'Kochi': 0.10830515645035063,\n",
       " 'Kolkata': -0.028641345427059706,\n",
       " 'Mumbai': 0.079088447967601172,\n",
       " 'New Delhi': 0.040414718257335225,\n",
       " 'Vijayawada': 0.11527100755450449,\n",
       " 'Visakhapatnam': 0.1044379146128946}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this if you wan to use downloaded csv file\n",
    "analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
